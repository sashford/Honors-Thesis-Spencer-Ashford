{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sashford/Honors-Thesis-Spencer-Ashford/blob/main/HonorsThesis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVFi1TVYXdcy"
      },
      "source": [
        "\n",
        "\n",
        "# SETUP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "saCJmxTIfy_s"
      },
      "outputs": [],
      "source": [
        "!sudo apt-get install ffmpeg libavcodec-extra\n",
        "!sudo apt-get install libopenblas-dev build-essential\n",
        "!sudo apt-get install python3 python-dev python3-dev\n",
        "!apt install subversion\n",
        "!svn checkout https://github.com/sashford/Honors-Thesis-Spencer-Ashford.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "v5RPQBGfyRe1"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms, datasets\n",
        "from torch.utils.data import DataLoader, random_split, Subset, Dataset\n",
        "from torch import nn\n",
        "from torch.nn.modules.loss import _Loss\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from sklearn import linear_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "bzYVhm_m0Del"
      },
      "outputs": [],
      "source": [
        "def npy_loader(path):\n",
        "    sonar_data = torch.from_numpy(np.load(path))\n",
        "    return sonar_data\n",
        "\n",
        "class SonarDataset(Dataset):\n",
        "  def __init__(self):\n",
        "\n",
        "    root_folder = \"/content/Honors-Thesis-Spencer-Ashford.git/trunk/dataset/\"\n",
        "    self.noise_folder = datasets.DatasetFolder(root=root_folder + 'noise', loader=npy_loader, extensions=['.npy'])\n",
        "    self.noiseless_folder = datasets.DatasetFolder(root=root_folder + 'noiseless',loader=npy_loader, extensions=['.npy'])\n",
        "\n",
        "  def __getitem__(self,index):\n",
        "    noisy = self.noise_folder[index]\n",
        "    noiseless = self.noiseless_folder[index]\n",
        "\n",
        "    if noisy[0].is_cuda:\n",
        "      return noisy[0], noiseless[0]\n",
        "    else:\n",
        "      return noisy[0].cuda(), noiseless[0].cuda()\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.noise_folder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "GHzSECpTpVNL"
      },
      "outputs": [],
      "source": [
        "data = SonarDataset()\n",
        "train_data, val_data = random_split(data, [0.85, 0.15])\n",
        "batch_size = 5\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size)\n",
        "val_loader = DataLoader(val_data, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WAR5Y67XpU-"
      },
      "source": [
        "# ENCODER/DECODER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "L7NkG3C5s8p0"
      },
      "outputs": [],
      "source": [
        "from torch.nn.modules.batchnorm import BatchNorm2d\n",
        "from torch.nn.modules.activation import ReLU\n",
        "\n",
        "channel_const_dimensions = [256, 15, 2]\n",
        "channel_const = np.prod(channel_const_dimensions)\n",
        "\n",
        "def init_weights(m):\n",
        "  if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
        "    torch.nn.init.xavier_uniform_(m.weight)\n",
        "    m.bias.data.fill_(0.01)\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "  def __init__(self, encoded_space_dim, fc2_input_dim):\n",
        "    super().__init__()\n",
        "\n",
        "    self.encoder_cnn = nn.Sequential(\n",
        "        nn.Conv2d(1, 1024, 7, stride=2, padding=3),\n",
        "        nn.BatchNorm2d(1024),\n",
        "        nn.ReLU(True),\n",
        "        nn.Conv2d(1024, 1024, 5, stride=2, padding=2),\n",
        "        nn.BatchNorm2d(1024),\n",
        "        nn.ReLU(True),\n",
        "        nn.Conv2d(1024, 1024, 3, stride=2, padding=1),\n",
        "        nn.BatchNorm2d(1024),\n",
        "        nn.ReLU(True),\n",
        "        nn.Conv2d(1024, 1024, 3, stride=2, padding=1),\n",
        "        nn.BatchNorm2d(1024),\n",
        "        nn.ReLU(True),\n",
        "        nn.Conv2d(1024, 256, 3, stride=2, padding=0),\n",
        "        nn.ReLU(True)\n",
        "    )\n",
        "\n",
        "    self.flatten = nn.Flatten(start_dim=1)\n",
        "\n",
        "    self.encoder_lin = nn.Sequential(\n",
        "        nn.Linear(channel_const, 128),\n",
        "        nn.ReLU(True),\n",
        "        nn.Linear(128, encoded_space_dim)\n",
        "    )\n",
        "\n",
        "    self.encoder_cnn.apply(init_weights)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = x.view(x.shape[0], 1 , 512, 90)\n",
        "    x = self.encoder_cnn(x)\n",
        "    x = self.flatten(x)\n",
        "    x = self.encoder_lin(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "  def __init__(self, encoded_space_dim, fc2_input_dim):\n",
        "    super().__init__()\n",
        "    self.decoder_lin = nn.Sequential(\n",
        "        nn.Linear(encoded_space_dim, 128),\n",
        "        nn.ReLU(True),\n",
        "        nn.Linear(128, channel_const),\n",
        "        nn.ReLU(True)\n",
        "    )\n",
        "\n",
        "    self.unflatten = nn.Unflatten(dim=1, unflattened_size=(channel_const_dimensions[0],channel_const_dimensions[1],channel_const_dimensions[2]))\n",
        "\n",
        "    self.decoder_conv = nn.Sequential(\n",
        "        nn.ConvTranspose2d(256, 1024, 3, stride=2, output_padding=(1,1)),\n",
        "        nn.BatchNorm2d(1024),\n",
        "        nn.ReLU(True),\n",
        "        nn.ConvTranspose2d(1024, 1024, 3, stride=2, padding=1, output_padding=(1,1)),\n",
        "        nn.BatchNorm2d(1024),\n",
        "        nn.ReLU(True),\n",
        "        nn.ConvTranspose2d(1024, 1024, 3, stride=2, padding=1, output_padding=(1,0)),\n",
        "        nn.BatchNorm2d(1024),\n",
        "        nn.ReLU(True),\n",
        "        nn.ConvTranspose2d(1024, 1024, 5, stride=2, padding=2, output_padding=(1,0)),\n",
        "        nn.BatchNorm2d(1024),\n",
        "        nn.ReLU(True),\n",
        "        nn.ConvTranspose2d(1024, 1, 7, stride=2, padding=3, output_padding=(1,1))\n",
        "    )\n",
        "\n",
        "    self.decoder_conv.apply(init_weights)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.decoder_lin(x)\n",
        "    x = self.unflatten(x)\n",
        "    x = self.decoder_conv(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSDBlDo2guAL"
      },
      "source": [
        "# Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "koKiW9dExL17"
      },
      "outputs": [],
      "source": [
        "loss_fn = torch.nn.L1Loss()\n",
        "lr = 0.0000001\n",
        "\n",
        "torch.manual_seed(0)\n",
        "\n",
        "d = 2\n",
        "\n",
        "encoder = Encoder(encoded_space_dim=d, fc2_input_dim=128)\n",
        "decoder = Decoder(encoded_space_dim=d, fc2_input_dim=128)\n",
        "\n",
        "params_to_optimize = [\n",
        "    {'params': encoder.parameters()},\n",
        "    {'params': decoder.parameters()}\n",
        "]\n",
        "\n",
        "optim = torch.optim.Adam(params_to_optimize, lr=lr, weight_decay=1e-05)\n",
        "\n",
        "encoder.cuda();\n",
        "decoder.cuda();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "9vMbhyGzzA1Y"
      },
      "outputs": [],
      "source": [
        "def train_epoch_den(encoder, decoder, dataloader, loss_fn, optimizer):\n",
        "  encoder.train()\n",
        "  decoder.train()\n",
        "  train_loss = []\n",
        "  i = 0\n",
        "  for noisy_image, noiseless_image in dataloader:\n",
        "    encoded_data = encoder(noisy_image)\n",
        "    decoded_data = decoder(encoded_data)\n",
        "\n",
        "    loss = loss_fn(decoded_data, noiseless_image)\n",
        "\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    print(f'\\t partial train loss {i} (single batch): {loss.data}| sizes: {decoded_data.size()}. {np.shape(noiseless_image)}')\n",
        "    train_loss.append(loss.detach().cpu().numpy())\n",
        "    i += 1\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "  return np.mean(train_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "CBZFKxk5zrhC"
      },
      "outputs": [],
      "source": [
        "from torch.serialization import normalize_storage_type\n",
        "def test_epoch_den(encoder, decoder, dataloader, loss_fn):\n",
        "  encoder.eval()\n",
        "  decoder.eval()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    conc_out = []\n",
        "    conc_label = []\n",
        "    for noisy_image, noiseless_image in dataloader:\n",
        "      if len(noisy_image) == batch_size:\n",
        "        encoded_data = encoder(noisy_image)\n",
        "        decoded_data = decoder(encoded_data)\n",
        "\n",
        "        output = decoded_data.cpu()\n",
        "        label = noiseless_image.cpu()\n",
        "\n",
        "        conc_out.append(output)\n",
        "        conc_label.append(label)\n",
        "\n",
        "\n",
        "    conc_out = torch.cat(conc_out)\n",
        "    conc_label = torch.cat(conc_label)\n",
        "\n",
        "    val_loss = loss_fn(conc_out, conc_label)\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "  return val_loss.data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eUip8ITNX15O"
      },
      "source": [
        "# Plotting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "XLqYq1160Dv6"
      },
      "outputs": [],
      "source": [
        "# Values come from the file used to create the simulation\n",
        "azi = 120\n",
        "binsA = 90\n",
        "minR = 1\n",
        "maxR = 30\n",
        "binsR = 512\n",
        "\n",
        "def plot_outputs(encoder, decoder):\n",
        "  index = np.random.randint(0, len(val_data))\n",
        "  img = val_data[index][0].unsqueeze(0)\n",
        "\n",
        "\n",
        "  encoder.eval()\n",
        "  decoder.eval()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    rec_img = decoder(encoder(img))\n",
        "\n",
        "\n",
        "  fig, (ax1, ax2, ax3) = plt.subplots(1,3,subplot_kw=dict(projection='polar'))\n",
        "\n",
        "  ax1.set_title(\"Noisy\")\n",
        "  ax1.set_theta_zero_location(\"N\")\n",
        "  ax1.set_thetamin(-azi/2)\n",
        "  ax1.set_thetamax(azi/2)\n",
        "  ax1.grid(False)\n",
        "\n",
        "  ax2.set_title(\"Denoised\")\n",
        "  ax2.set_theta_zero_location(\"N\")\n",
        "  ax2.set_thetamin(-azi/2)\n",
        "  ax2.set_thetamax(azi/2)\n",
        "  ax2.grid(False)\n",
        "\n",
        "  ax3.set_title(\"Noiseless\") # Ground Truth Values\n",
        "  ax3.set_theta_zero_location(\"N\")\n",
        "  ax3.set_thetamin(-azi/2)\n",
        "  ax3.set_thetamax(azi/2)\n",
        "  ax3.grid(False)\n",
        "\n",
        "  theta = np.linspace(-azi/2, azi/2, binsA) * np.pi / 180\n",
        "  r = np.linspace(minR, maxR, binsR)\n",
        "  T, R = np.meshgrid(theta,r)\n",
        "  z = np.zeros_like(T)\n",
        "\n",
        "  plot_noise = ax1.pcolormesh(T, R, z, cmap='gray', shading='auto', vmin=0, vmax=1)\n",
        "  plot_denoised = ax2.pcolormesh(T, R, z, cmap='gray', shading='auto', vmin=0, vmax=1)\n",
        "  plot_noiseless = ax3.pcolormesh(T, R, z, cmap='gray', shading='auto', vmin=0, vmax=1)\n",
        "  plt.tight_layout()\n",
        "\n",
        "  plot_noise.set_array(img.cpu().squeeze().numpy().ravel())\n",
        "  plot_denoised.set_array(rec_img.cpu().squeeze().numpy().ravel())\n",
        "  plot_noiseless.set_array(val_data[index][1].cpu().squeeze().numpy().ravel())\n",
        "\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29vzklQVX_9b"
      },
      "source": [
        "# Train Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "liCdXJrC4MHw"
      },
      "outputs": [],
      "source": [
        "num_epochs = 90\n",
        "history_da={'train_loss':[], 'val_loss':[]}\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  print(f'EPOCH {epoch + 1}/{num_epochs}')\n",
        "  train_loss=train_epoch_den(\n",
        "    encoder=encoder,\n",
        "    decoder=decoder,\n",
        "    dataloader=train_loader,\n",
        "    loss_fn=loss_fn,\n",
        "    optimizer=optim)\n",
        "  print(\"beginning validation\")\n",
        "  val_loss = test_epoch_den(\n",
        "      encoder=encoder,\n",
        "      decoder=decoder,\n",
        "      dataloader=val_loader,\n",
        "      loss_fn=loss_fn,\n",
        "  )\n",
        "  print(\"begin plotting\")\n",
        "  history_da['train_loss'].append(train_loss)\n",
        "  history_da['val_loss'].append(val_loss)\n",
        "  print('\\n EPOCH {}/{} \\t train loss {:.3f} \\t val loss {:.3f}'.format(epoch + 1, num_epochs,train_loss,val_loss))\n",
        "  plot_outputs(encoder,decoder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tbKqxRTBe6om"
      },
      "outputs": [],
      "source": [
        "# Optional Cell, plays a sound to indicate when training has finished\n",
        "import librosa\n",
        "from IPython.display import display, Audio\n",
        "\n",
        "# for playing wav file\n",
        "sound, rate = librosa.load(\"/content/drive/MyDrive/EndTrainingLoop.wav\")\n",
        "print('playing sound using  pydub')\n",
        "display(Audio(sound, rate=rate, autoplay=True))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "mount_file_id": "14jh_ljfLnlT2vT9M6d5e_AJWefrIbJb0",
      "authorship_tag": "ABX9TyO+n/RNz7p0uYjMe1Piw3QX",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}